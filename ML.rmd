---

author: "JuChul Shin"
date: "04/26/2015"

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

```{r echo=FALSE, message=FALSE}
library(caret)
```

### Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit, it is now possible to collect a large amount of data about personal activity relatively inexpensively.  These type of devices are part of the quantified self movement--a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech enthusiasts.  One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  Participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways.  In this project, the goal was to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did their exercise.

### Inspecting and Cleaning the Dataset

```{r echo=FALSE, results='hide'}
# load data
testing.original <- read.csv("data/pml-testing.csv",na.strings=c("NA","#DIV/0!",""))
training.original <- read.csv("data/pml-training.csv",na.strings=c("NA","#DIV/0!",""))
colSums(is.na(training.original)) # lots of NAs!

cleanData <- function(df) {
  naCounts <- colSums(is.na(df))
  naColumns <- names(naCounts[!naCounts %in% 0]) # 100 columns
  administrativeColumns <- names(df)[1:6] # X, user_name, raw_timestamp_part_1/2,
                                          # cvtd_timestamp, new_window,
                                          # num_window (7 columns)
  columnsToRemove <- c(naColumns, administrativeColumns)
  df <- df[, -which(names(df) %in% columnsToRemove)]

  return(df)
}

testing <- cleanData(testing.original)
training <- cleanData(training.original)
training$classe <- factor(training$classe)
rm(testing.original, training.original)
```

The dataset came pre-partitioned into 19622 training set records and 20 test set records. Of the 160 variables, I removed 100, which contained large occurrences of `NA` values (e.g. blank, zero-division errors, etc.).  I also removed the first 7 variables, which did not contain relevant feature data (e.g. user names and timestamps).

### Applying Machine Learning Algorithms

I used two classifiers: stochastic gradient boosting and random forest.  The random forest took noticeably longer to compute, but had perfect accuracy and performance.  With such high performance, I expected the results on the 20 records in the test set to be near-perfect accuracy.

```{r results='hide', message=FALSE}
# control parameters
cvTrainControl = trainControl(method = "cv", number = 3,
                              repeats = 1, p = 0.6)

# gradient boosting classifier
clfGbm          <- train(classe ~ ., data = training,
                         method = "gbm", trControl = cvTrainControl)

# random forest classifier
clfRandomForest <- train(classe ~ ., data = training,
                         method = "rf", trControl = cvTrainControl)
```

```{r echo=FALSE}
clfRandomForest
confusionMatrix(predict(clfRandomForest, training), training$classe)
```

### Predicting Labels in the Test Data

Using the random forest classifier, I made the following predictions in the testing data.  Results were exported to `.txt` files and submitted with 100% accuracy!

```{r echo=FALSE}
predictions = predict(clfRandomForest, testing)
predictions
```

```{r echo=FALSE, results='hide'}
pml_write_files = function(x) {
  n = length(x)
  for(i in 1:n){
    filename = paste0('predictions/problem_id_', i, '.txt')
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictions)
```


